{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a02091e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\spark-3.4.0-bin-hadoop3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark \n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdd565c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark \n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext(\"local\",\"Matrix Vector Multiplication\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9ce44c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, posexplode, collect_list, first\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0a5f8c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix1 = sc.textFile(r\"C:\\Users\\Gurudeep\\Desktop\\spark-warehouse\\Matrix.txt\")\n",
    "matrix2 = sc.textFile(r\"C:\\Users\\Gurudeep\\Desktop\\spark-warehouse\\Vector.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ed0696f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1 2 2.5', '1 3 1', '2 1 4', '2 4 -2', '3 3 -1.5', '4 1 8']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix1.take(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4ff11698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '0', '2']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix2.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3c13345f",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix1 = matrix1.map(lambda line: line.split()).map(lambda cols: [float(cols[0]), float(cols[1]), float(cols[2])])\n",
    "matrix2 = matrix2.map(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6b909bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0, 2.0, 2.5],\n",
       " [1.0, 3.0, 1.0],\n",
       " [2.0, 1.0, 4.0],\n",
       " [2.0, 4.0, -2.0],\n",
       " [3.0, 3.0, -1.5],\n",
       " [4.0, 1.0, 8.0]]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix1.take(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "66155be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 2]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix2.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d867261e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the multiplication factors\n",
    "result_rdd = matrix1.zip(matrix2).map(lambda x: [elem * factor for elem, factor in zip(x[0], x[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7c34f3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix1_list = matrix1.collect()\n",
    "transposed_matrix = list(zip(*matrix1_list))\n",
    "# Define the second RDD\n",
    "#rdd2 = spark.sparkContext.parallelize([2, 4, 6])\n",
    "\n",
    "# Create an RDD from the matrix\n",
    "rdd1 = spark.sparkContext.parallelize(transposed_matrix)\n",
    "\n",
    "# Multiply the matrix (rdd1) with the second RDD (rdd2) element-wise\n",
    "result_rdd = rdd1.zip(matrix2).map(lambda x: [elem * x[1] for elem in x[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4b684711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.0, 1.0, 2.0, 2.0, 3.0, 4.0),\n",
       " (2.0, 3.0, 1.0, 4.0, 3.0, 1.0),\n",
       " (2.5, 1.0, 4.0, -2.0, -1.5, 8.0)]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transposed_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8ca9137c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0, 1.0, 2.0, 2.0, 3.0, 4.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [5.0, 2.0, 8.0, -4.0, -3.0, 16.0]]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_rdd.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5810185c",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_matrix_rdd = spark.sparkContext.parallelize([\n",
    "    result_rdd.map(lambda sublist: sublist[0]).reduce(lambda a, b: a + b),\n",
    "    result_rdd.map(lambda sublist: sublist[1]).reduce(lambda a, b: a + b),\n",
    "    result_rdd.map(lambda sublist: sublist[2]).reduce(lambda a, b: a + b),\n",
    "    result_rdd.map(lambda sublist: sublist[3]).reduce(lambda a, b: a + b),\n",
    "    result_rdd.map(lambda sublist: sublist[4]).reduce(lambda a, b: a + b),\n",
    "    result_rdd.map(lambda sublist: sublist[5]).reduce(lambda a, b: a + b)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1e20980b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.0, 3.0, 10.0, -2.0, 0.0, 20.0]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_matrix_rdd.take(6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
